{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c663f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Whisper Sanskrit Fine-tuning Notebook\n",
    "# \n",
    "# This notebook provides an interactive way to fine-tune Whisper on Sanskrit audio data.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup and Imports\n",
    "\n",
    "# %%\n",
    "# Import all necessary modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom modules\n",
    "from config import Config\n",
    "from audio_preprocessor import AudioPreprocessor\n",
    "from data_utils import (\n",
    "    parse_transcript_file,\n",
    "    prepare_data_splits,\n",
    "    DatasetProcessor,\n",
    "    combine_transcript_with_audio\n",
    ")\n",
    "from training_utils import (\n",
    "    WhisperTrainingCallback,\n",
    "    MetricsComputer,\n",
    "    create_data_collator\n",
    ")\n",
    "from inference import WhisperSanskritTranscriber, evaluate_on_test_set\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Configuration\n",
    "\n",
    "# %%\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "# Modify configuration as needed\n",
    "config.model_name = \"openai/whisper-small\"  # Change to tiny/base/small/medium/large\n",
    "config.batch_size = 16  # Adjust based on your GPU memory\n",
    "config.max_steps = 4000  # Adjust based on dataset size\n",
    "config.learning_rate = 1e-5\n",
    "\n",
    "# Display configuration\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Data Preparation\n",
    "\n",
    "# %%\n",
    "# Parse transcript file\n",
    "print(\"Parsing transcript file...\")\n",
    "transcript_data = parse_transcript_file(config.transcript_file)\n",
    "print(f\"Found {len(transcript_data)} transcript entries\")\n",
    "\n",
    "# Display sample entries\n",
    "print(\"\\nSample entries:\")\n",
    "for i, item in enumerate(transcript_data[:3]):\n",
    "    print(f\"\\n{i+1}. Audio: {item['audio_filename']}\")\n",
    "    print(f\"   Transcript: {item['transcript'][:100]}...\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Audio Preprocessing\n",
    "\n",
    "# %%\n",
    "# Initialize audio preprocessor\n",
    "audio_preprocessor = AudioPreprocessor(config.cache_dir, config.sample_rate)\n",
    "\n",
    "# Convert audio files\n",
    "print(\"Converting audio files from M4A to WAV...\")\n",
    "audio_files = [item['audio_filename'] for item in transcript_data]\n",
    "converted_paths = audio_preprocessor.convert_audio_batch(audio_files, config.audio_dir)\n",
    "\n",
    "print(f\"\\nSuccessfully converted {len(converted_paths)} audio files\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Combine Data and Create Splits\n",
    "\n",
    "# %%\n",
    "# Combine transcript data with converted audio paths\n",
    "combined_data = combine_transcript_with_audio(transcript_data, converted_paths)\n",
    "\n",
    "# Create train/val/test splits\n",
    "train_data, val_data, test_data = prepare_data_splits(combined_data, config)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Initialize Model and Processor\n",
    "\n",
    "# %%\n",
    "# Load Whisper model and processor\n",
    "print(f\"Loading Whisper model: {config.model_name}\")\n",
    "processor = WhisperProcessor.from_pretrained(config.model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(config.model_name)\n",
    "\n",
    "# Configure for Sanskrit\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.generation_config.language = config.language\n",
    "model.generation_config.task = config.task\n",
    "\n",
    "# Move to device\n",
    "model.to(config.device)\n",
    "print(f\"Model loaded on {config.device}\")\n",
    "print(f\"Total parameters: {model.num_parameters():,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Create Datasets\n",
    "\n",
    "# %%\n",
    "# Initialize dataset processor\n",
    "dataset_processor = DatasetProcessor(processor, config.sample_rate)\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = dataset_processor.prepare_dataset(\n",
    "    train_data, audio_preprocessor, config.max_duration\n",
    ")\n",
    "val_dataset = dataset_processor.prepare_dataset(\n",
    "    val_data, audio_preprocessor, config.max_duration\n",
    ")\n",
    "test_dataset = dataset_processor.prepare_dataset(\n",
    "    test_data, audio_preprocessor, config.max_duration\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Validation: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Setup Training\n",
    "\n",
    "# %%\n",
    "# Create training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    max_steps=config.max_steps,\n",
    "    gradient_checkpointing=config.gradient_checkpointing,\n",
    "    fp16=config.fp16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=config.eval_steps,\n",
    "    save_steps=config.save_steps,\n",
    "    logging_steps=config.logging_steps,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=config.load_best_model_at_end,\n",
    "    metric_for_best_model=config.metric_for_best_model,\n",
    "    greater_is_better=config.greater_is_better,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=config.generation_max_length,\n",
    "    save_total_limit=config.save_total_limit,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# Create data collator\n",
    "data_collator = create_data_collator(processor, model)\n",
    "\n",
    "# Create metrics computer\n",
    "compute_metrics = MetricsComputer(processor)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks=[WhisperTrainingCallback()],\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Start Training\n",
    "# \n",
    "# **Note**: Training will take time depending on your dataset size and GPU.\n",
    "\n",
    "# %%\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "print(f\"Total steps: {config.max_steps}\")\n",
    "print(f\"Evaluation every {config.eval_steps} steps\")\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model()\n",
    "processor.save_pretrained(config.output_dir)\n",
    "\n",
    "print(f\"\\nModel saved to: {config.output_dir}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Evaluate on Test Set\n",
    "\n",
    "# %%\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for key, value in test_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Test the Fine-tuned Model\n",
    "\n",
    "# %%\n",
    "# Initialize transcriber with fine-tuned model\n",
    "transcriber = WhisperSanskritTranscriber(config.output_dir)\n",
    "\n",
    "# Test on a few examples\n",
    "print(\"Testing fine-tuned model:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, item in enumerate(test_data[:5]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Audio: {item['original_filename']}\")\n",
    "    \n",
    "    # Transcribe\n",
    "    result = transcriber.transcribe(item['audio'])\n",
    "    \n",
    "    print(f\"True: {item['transcript']}\")\n",
    "    print(f\"Pred: {result['text']}\")\n",
    "    print(f\"Duration: {result['duration']:.2f}s\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Detailed Evaluation\n",
    "\n",
    "# %%\n",
    "# Perform detailed evaluation\n",
    "detailed_results = evaluate_on_test_set(\n",
    "    transcriber,\n",
    "    test_data,\n",
    "    os.path.join(config.output_dir, \"detailed_test_results.json\")\n",
    ")\n",
    "\n",
    "print(\"\\nDetailed Evaluation Metrics:\")\n",
    "for key, value in detailed_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Interactive Transcription\n",
    "# \n",
    "# Use this cell to transcribe any audio file with your fine-tuned model.\n",
    "\n",
    "# %%\n",
    "# Example: Transcribe a new audio file\n",
    "def transcribe_audio(audio_path: str):\n",
    "    \"\"\"Transcribe any audio file\"\"\"\n",
    "    result = transcriber.transcribe(audio_path)\n",
    "    print(f\"Audio: {audio_path}\")\n",
    "    print(f\"Transcription: {result['text']}\")\n",
    "    print(f\"Duration: {result['duration']:.2f}s\")\n",
    "    return result\n",
    "\n",
    "# Uncomment to use:\n",
    "# transcribe_audio(\"path/to/your/audio.m4a\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14. Save Training Summary\n",
    "\n",
    "# %%\n",
    "import json\n",
    "\n",
    "# Save training summary\n",
    "summary = {\n",
    "    \"model_name\": config.model_name,\n",
    "    \"language\": config.language,\n",
    "    \"train_samples\": len(train_dataset),\n",
    "    \"val_samples\": len(val_dataset),\n",
    "    \"test_samples\": len(test_dataset),\n",
    "    \"final_wer\": test_results.get(\"eval_wer\", None),\n",
    "    \"training_steps\": train_result.global_step,\n",
    "    \"device\": str(config.device)\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(config.output_dir, \"training_summary.json\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Training Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 15. Next Steps\n",
    "# \n",
    "# 1. **Use the model**: Load it with `WhisperSanskritTranscriber(\"./whisper_sanskrit_finetuned\")`\n",
    "# 2. **Share the model**: Upload to Hugging Face Hub\n",
    "# 3. **Create API**: Wrap in FastAPI for serving\n",
    "# 4. **Optimize**: Convert to ONNX for faster inference\n",
    "# 5. **Improve**: Collect more data and retrain"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
